# CS231N Course for Deep Learning and Computer Vision
# Reference
- [课程讲义作业](http://vision.stanford.edu/teaching/cs231n/syllabus.html)
- [课程视频](https://space.bilibili.com/216720985/channel/detail?cid=32406)
- [课程笔记翻译](https://zhuanlan.zhihu.com/p/21930884)

## 1 Introduction
课程从回顾人类的进化历史开始讲述，生物进化开始加快的一个标志点就是生物进化处了视觉功能，视觉信息的理解也是非常困难的事情，人类大脑处理视觉的信息的部分占比超过了50%，数以亿计的神经元同时工作用于处理视觉信息。

在上世纪60年代的时候，计算机视觉还没有开始为人所认知，甚至计算机还是很稀有的设备。科学家们在对图像进行研究的过程中，最开始希望能分类图像，但是发现任务太难了，然后转为分割图像，提取图像特征，比如SIFT特征。

李飞飞等人创立了ImageNet，这是一个超大的image数据集，在2012年的比赛中其中一个团队对图像的识别算法打败了其他所有的团队，并且错误率也从上一年的25%降到了16%，这种算法就是使用CNN，再往后DNN就慢慢发展开来。

计算机理解图像的几个应用方向：

- 语义分割
- 图像理解转成文字
- 图片的风格迁移

在计算机如何对图像进行更深层次的理解领域仍然存在有大量需要解决的问题，really amzaing！

## 2 Image Classification
图像分类的难点是semantic gap，就是由于摄像机视角、照明、object变形和遮挡的时候，image的pixels发生了很大的变化，但是image的语义并没有改变，object也没有改变。

如何比较两个image的相似性？一个朴素的想法是使用曼哈顿距离去描述。

数据驱动方法：给计算机很多数据，然后实现学习算法，让计算机学习到每个类的外形。

图像分类可以分解为两个过程，trainning和predicting，我们希望trainning是O(N)的，predicting是O(1)的，因为trainning我们可以在数据运算中心完成，predicting希望是能够实时运行的。但是KNN算法进行图像分类与此相反，它的trainning只需要记录数据是O(1)时间，predicting需要查找，时间是O(N)的。

### 2.1 KNN分类器
使用距离来度量图片之间的相似性，KNN中两个比较重要的参数是K值的选取和距离度量方式的选取。这连个参数也称为超参数(hyperparameter)。

几个数据集的区别：

- 训练集Trainning Set：
带有label的用于训练的数据
- 测试集 Testing Set：
实际生产环境的没有label的真实数据， 测试数据集只使用一次，即在训练完成后评价最终的模型时使用
- 验证集 Validation Set：
验证集其实就是作为假的测试集来调优。调优的一种方法是使用交叉验证(Cross Validation),比如使用5-fold，将训练集平均分成5份，其中4份用来训练，1份用来验证。然后我们循环着取其中4份来训练，其中1份来验证，最后取所有5次验证结果的平均值作为算法验证结果。

**决不能使用测试集来进行调优！！！**

当你在设计机器学习算法的时候，应该把测试集看做非常珍贵的资源，不到最后一步，绝不使用它。如果你使用测试集来调优，而且算法看起来效果不错，那么真正的危险在于：算法实际部署后，性能可能会远低于预期。这种情况，称之为算法对测试集过拟合（overfitting）。

衡量一个算法性能的好坏还有一个指标就是算法的泛化能力(generalization),表示算法在未见过的数据集上表现的性能好坏，也就是在Testing Set上的表现。

